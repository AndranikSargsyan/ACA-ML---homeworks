{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>full_sq</th>\n",
       "      <th>life_sq</th>\n",
       "      <th>floor</th>\n",
       "      <th>max_floor</th>\n",
       "      <th>material</th>\n",
       "      <th>build_year</th>\n",
       "      <th>num_room</th>\n",
       "      <th>kitch_sq</th>\n",
       "      <th>...</th>\n",
       "      <th>cafe_count_5000_price_1500</th>\n",
       "      <th>cafe_count_5000_price_2500</th>\n",
       "      <th>cafe_count_5000_price_4000</th>\n",
       "      <th>cafe_count_5000_price_high</th>\n",
       "      <th>big_church_count_5000</th>\n",
       "      <th>church_count_5000</th>\n",
       "      <th>mosque_count_5000</th>\n",
       "      <th>leisure_count_5000</th>\n",
       "      <th>sport_count_5000</th>\n",
       "      <th>market_count_5000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-08-20</td>\n",
       "      <td>43</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-08-23</td>\n",
       "      <td>34</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-08-27</td>\n",
       "      <td>43</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>89</td>\n",
       "      <td>50.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>552</td>\n",
       "      <td>319</td>\n",
       "      <td>108</td>\n",
       "      <td>17</td>\n",
       "      <td>135</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>195</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-06</td>\n",
       "      <td>67</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>62</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2011-09-08</td>\n",
       "      <td>25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>81</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>127</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-09</td>\n",
       "      <td>44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-10</td>\n",
       "      <td>42</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2011-09-13</td>\n",
       "      <td>36</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   timestamp  full_sq  life_sq  floor  max_floor  material  build_year  \\\n",
       "0   1  2011-08-20       43     27.0    4.0        NaN       NaN         NaN   \n",
       "1   2  2011-08-23       34     19.0    3.0        NaN       NaN         NaN   \n",
       "2   3  2011-08-27       43     29.0    2.0        NaN       NaN         NaN   \n",
       "3   4  2011-09-01       89     50.0    9.0        NaN       NaN         NaN   \n",
       "4   5  2011-09-05       77     77.0    4.0        NaN       NaN         NaN   \n",
       "5   6  2011-09-06       67     46.0   14.0        NaN       NaN         NaN   \n",
       "6   7  2011-09-08       25     14.0   10.0        NaN       NaN         NaN   \n",
       "7   8  2011-09-09       44     44.0    5.0        NaN       NaN         NaN   \n",
       "8   9  2011-09-10       42     27.0    5.0        NaN       NaN         NaN   \n",
       "9  10  2011-09-13       36     21.0    9.0        NaN       NaN         NaN   \n",
       "\n",
       "   num_room  kitch_sq        ...          cafe_count_5000_price_1500  \\\n",
       "0       NaN       NaN        ...                                  40   \n",
       "1       NaN       NaN        ...                                  36   \n",
       "2       NaN       NaN        ...                                  25   \n",
       "3       NaN       NaN        ...                                  15   \n",
       "4       NaN       NaN        ...                                 552   \n",
       "5       NaN       NaN        ...                                 155   \n",
       "6       NaN       NaN        ...                                 144   \n",
       "7       NaN       NaN        ...                                  36   \n",
       "8       NaN       NaN        ...                                  69   \n",
       "9       NaN       NaN        ...                                  30   \n",
       "\n",
       "  cafe_count_5000_price_2500 cafe_count_5000_price_4000  \\\n",
       "0                          9                          4   \n",
       "1                         15                          3   \n",
       "2                         10                          3   \n",
       "3                         11                          2   \n",
       "4                        319                        108   \n",
       "5                         62                         14   \n",
       "6                         81                         16   \n",
       "7                          9                          4   \n",
       "8                         19                          8   \n",
       "9                         19                         13   \n",
       "\n",
       "   cafe_count_5000_price_high  big_church_count_5000  church_count_5000  \\\n",
       "0                           0                     13                 22   \n",
       "1                           0                     15                 29   \n",
       "2                           0                     11                 27   \n",
       "3                           1                      4                  4   \n",
       "4                          17                    135                236   \n",
       "5                           1                     53                 78   \n",
       "6                           3                     38                 80   \n",
       "7                           0                     11                 18   \n",
       "8                           1                     18                 34   \n",
       "9                           0                     10                 20   \n",
       "\n",
       "   mosque_count_5000  leisure_count_5000  sport_count_5000  market_count_5000  \n",
       "0                  1                   0                52                  4  \n",
       "1                  1                  10                66                 14  \n",
       "2                  0                   4                67                 10  \n",
       "3                  0                   0                26                  3  \n",
       "4                  2                  91               195                 14  \n",
       "5                  1                  20               113                 17  \n",
       "6                  1                  27               127                  8  \n",
       "7                  1                   0                47                  4  \n",
       "8                  1                   3                85                 11  \n",
       "9                  1                   3                67                  1  \n",
       "\n",
       "[10 rows x 291 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import geopy\n",
    "from geopy.geocoders import Yandex\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "y = df['price_doc'].values\n",
    "df = df.drop(columns=['price_doc'])\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geolocator = Yandex()\n",
    "\n",
    "def do_geocode(address, trial=0):\n",
    "    try:\n",
    "        location = geolocator.geocode(address)\n",
    "        if location == None:\n",
    "            return \"NaN\", \"NaN\"\n",
    "        return location.latitude, location.longitude\n",
    "    except Exception as e:\n",
    "        if trial > 3:\n",
    "            return \"NaN\", \"NaN\"\n",
    "        else:\n",
    "            return do_geocode(address, trial + 1)\n",
    "        time.sleep(2)\n",
    "        \n",
    "def load_pickle(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_pickle(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoDataTransformer(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.cache = {}\n",
    "        self.pickle_path = './data/locations.pkl'\n",
    "        self.imp = Imputer(strategy='median')\n",
    "        \n",
    "        if os.path.isfile(self.pickle_path):\n",
    "            self.cache = load_pickle(self.pickle_path)\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "                \n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        locations = []\n",
    "        for sub_area in df['sub_area']:\n",
    "            if sub_area in self.cache:\n",
    "                latitude, longitude = self.cache[sub_area]\n",
    "                if latitude == 'NA' or longitude == 'NA':\n",
    "                    locations.append(['NaN', 'NaN'])\n",
    "                else:\n",
    "                    locations.append([latitude, longitude])\n",
    "            else:\n",
    "                latitude, longitude = do_geocode(sub_area)\n",
    "                self.cache[sub_area] = [latitude, longitude]\n",
    "                locations.append([latitude, longitude])\n",
    "        \n",
    "        locations = np.array(locations)\n",
    "        locations = self.imp.fit_transform(locations)\n",
    "        \n",
    "        lat = locations[:, 0]\n",
    "        lon = locations[:, 1]\n",
    "\n",
    "        df_copy['x'] = np.cos(lat) * np.cos(lon)\n",
    "        df_copy['y'] = np.cos(lat) * np.sin(lon)\n",
    "        df_copy['z'] = np.sin(lat)\n",
    "        \n",
    "        df_copy = df_copy.drop(columns=['sub_area'])\n",
    "        \n",
    "        if not os.path.isfile(self.pickle_path):\n",
    "            save_pickle(cache, self.pickle_path)\n",
    "            \n",
    "        return df_copy\n",
    "\n",
    "class MultiColumnLabelEncoder(TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.encoders = {}\n",
    "        self.columns = columns\n",
    "    def fit(self, df, y=None):\n",
    "        for column in self.columns:\n",
    "            self.encoders[column] = LabelEncoder().fit(df[column])\n",
    "        return self\n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        for column in self.columns:\n",
    "            df_copy[column] = self.encoders[column].transform(df_copy[column].fillna(df[column].iloc[0]))\n",
    "        return df_copy\n",
    "    \n",
    "class DateTransformer(TransformerMixin):    \n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        df_copy['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "        df_copy['timestamp'] = pd.to_numeric(df_copy['timestamp'])\n",
    "        return df_copy\n",
    "    \n",
    "class UnnecessaryColumnsDroper(TransformerMixin):\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        df_copy = df_copy.drop(columns=['id'], axis=1)\n",
    "        return df_copy\n",
    "    \n",
    "class FeatureSelector(TransformerMixin):\n",
    "    def __init__(self):\n",
    "        to_drop = []\n",
    "    \n",
    "    def fit(self, df, y=None):\n",
    "        df = pd.DataFrame(df)\n",
    "        corr_matrix = df.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "        self.to_drop = to_drop\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df = pd.DataFrame(df)\n",
    "        df = df.drop(df.columns[self.to_drop], axis=1)\n",
    "        return df\n",
    "    \n",
    "class MyRegression(TransformerMixin):\n",
    "    def fit(self, df, y=None):\n",
    "        self.model = RidgeCV(alphas=(0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500))\n",
    "        self.model.fit(df, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        values = self.model.predict(df)\n",
    "        df_copy = np.column_stack([df_copy, values])\n",
    "        return df_copy\n",
    "    \n",
    "    \n",
    "class MyXGBoost(TransformerMixin):\n",
    "    def fit(self, df, y=None):\n",
    "        xgb_model = xgb.XGBRegressor()\n",
    "        params = {\n",
    "            'gamma': [0.5, 1, 2],\n",
    "            'max_depth': [3, 4, 5]\n",
    "        }\n",
    "        grid_search = GridSearchCV(\n",
    "            xgb_model,\n",
    "            param_grid=params,\n",
    "            n_jobs=4\n",
    "        )\n",
    "        self.model = grid_search\n",
    "        self.model.fit(df, y)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        df_copy = df.copy()\n",
    "        values = self.model.predict(df)\n",
    "        df_copy = np.column_stack([df_copy, values])\n",
    "        return df_copy\n",
    "    \n",
    "columns_to_encode = [\n",
    "    'product_type',\n",
    "    'culture_objects_top_25',\n",
    "    'thermal_power_plant_raion',\n",
    "    'incineration_raion',\n",
    "    'oil_chemistry_raion',\n",
    "    'radiation_raion',\n",
    "    'railroad_terminal_raion',\n",
    "    'railroad_1line',\n",
    "    'big_market_raion',\n",
    "    'nuclear_reactor_raion',\n",
    "    'detention_facility_raion',\n",
    "    'water_1line',\n",
    "    'big_road1_1line',\n",
    "    'ecology',\n",
    "]\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    GeoDataTransformer(),\n",
    "    MultiColumnLabelEncoder(columns_to_encode),\n",
    "    DateTransformer(),\n",
    "    UnnecessaryColumnsDroper(),\n",
    "    Imputer(strategy='median'),\n",
    "    FeatureSelector(),\n",
    "    StandardScaler(),\n",
    "    MyRegression(),\n",
    "    MyXGBoost(),\n",
    "    xgb.XGBRegressor(max_depth=3)\n",
    ")\n",
    "\n",
    "model = pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22096666832438175"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.abs(model.predict(X_test))\n",
    "mean_squared_log_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')\n",
    "model = pipe.fit(df, y)\n",
    "result = pd.DataFrame(df_test['id'])\n",
    "result['price_doc'] = np.abs(model.predict(df_test))\n",
    "result.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Score on Kaggle: 0.33478"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
